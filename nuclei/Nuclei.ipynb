{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from subprocesss import check_output\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "\n",
    "\n",
    "size_height = 256\n",
    "size_width = 256\n",
    "size_channel = 3\n",
    "\n",
    "train_image_id = check_output([\"ls\", \"stage1_train/\"]).decode(\"utf8\").split()\n",
    "test_image_id = check_output([\"ls\", \"stage1_test/\"]).decode(\"utf8\").split()\n",
    "\n",
    "X_train = np.zeros((len(train_image_id), size_height, size_width, size_channel), dtype=np.uint8)\n",
    "X_test = np.zeros((len(test_image_id), size_height, size_width, size_channel), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_image_id), size_height, size_width, 1), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [04:43<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for ii, image_id in tqdm(enumerate(train_image_id), total=len(train_image_id)):\n",
    "    path = \"stage1_train/{}/images/{}.png\".format(image_id,image_id)\n",
    "    image = imread(path)[:,:,:size_channel]\n",
    "    image = resize(image, (size_height, size_width), mode='constant', preserve_range=True)\n",
    "    X_train[ii] = image\n",
    "    mask_path = \"stage1_train/{}/masks/*.png\".format(image_id)\n",
    "    mask = np.zeros((size_height, size_width, 1), dtype=np.bool)\n",
    "    masks = imread_collection(mask_path).concatenate()\n",
    "    for msk in masks:\n",
    "        msk = np.expand_dims(resize(msk, (size_height, size_width), mode='constant', \\\n",
    "              preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, msk)\n",
    "    Y_train[ii] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(128,128))\n",
    "#ax[0].imshow(X_train[0])\n",
    "#ax[1].imshow(np.squeeze(Y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:02<00:00, 29.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for ii, image_id in tqdm(enumerate(test_image_id), total=len(test_image_id)):\n",
    "    path = \"stage1_test/{}/images/{}.png\".format(image_id,image_id)\n",
    "    image = imread(path)[:,:,:size_channel]\n",
    "    image = resize(image, (size_height, size_width), mode='constant', preserve_range=True)\n",
    "    X_test[ii] = image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import UpSampling2D, Lambda, Merge\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    X_input = Lambda(lambda x: x/255.0)(inputs)\n",
    "    \n",
    "    # Down block 1\n",
    "    conv1 = Conv2D(16, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(X_input)\n",
    "    conv2 = Conv2D(16, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    maxpool1 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    # Down block 2\n",
    "    conv3 = Conv2D(32, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(maxpool1)\n",
    "    conv4 = Conv2D(32, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    maxpool2 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "    \n",
    "    # Down block 3\n",
    "    conv5 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(maxpool2)\n",
    "    conv6 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    maxpool3 = MaxPooling2D(pool_size=(2,2))(conv6)\n",
    "    \n",
    "    # Down block 4\n",
    "    conv7 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(maxpool3)\n",
    "    conv8 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    maxpool4 = MaxPooling2D(pool_size=(2,2))(conv8)\n",
    "    \n",
    "    # Vertical block\n",
    "    conv9 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(maxpool4)\n",
    "    conv10 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    upsampling1 = UpSampling2D(size=(2,2))(conv10)\n",
    "    concate1 = concatenate([upsampling1, conv8])\n",
    "    \n",
    "    # Up block 1\n",
    "    conv11 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(concate1)\n",
    "    conv12 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv11)\n",
    "    upsampling2 = UpSampling2D(size=(2,2))(conv12)\n",
    "    concate2 = concatenate([upsampling2, conv6])\n",
    "    \n",
    "    # Up block 2\n",
    "    conv13 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(concate2)\n",
    "    conv14 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv13)\n",
    "    upsampling3 = UpSampling2D(size=(2,2))(conv14)\n",
    "    concate3 = concatenate([upsampling3, conv4])\n",
    "    \n",
    "    # Up block 3\n",
    "    conv15 = Conv2D(32, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(concate3)\n",
    "    conv16 = Conv2D(32, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv15)\n",
    "    upsampling4 = UpSampling2D(size=(2,2))(conv16)\n",
    "    concate4 = concatenate([upsampling4, conv2])\n",
    "    \n",
    "    # Up block 4\n",
    "    conv17 = Conv2D(16, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(concate4)\n",
    "    conv18 = Conv2D(16, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv17)\n",
    "    \n",
    "    # output\n",
    "    outputs = Conv2D(1, (1,1), activation='sigmoid', padding='same', kernel_initializer='he_normal')(conv18)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 256, 256, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 64) 1792        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 128, 128, 64) 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 128 147584      conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 64, 64, 128)  0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 256)  0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 16, 16, 512)  0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 1536) 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 512)  7078400     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 768)  0           up_sampling2d_5[0][0]            \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 384 0           up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 128 442496      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 128, 128, 128 147584      conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_7[0][0]            \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 256, 256, 1)  65          conv2d_51[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,378,945\n",
      "Trainable params: 31,378,945\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet((size_height, size_width, size_channel))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define metrics and loss function\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[mean_iou])\n",
    "cb = [keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, \\\n",
    "     verbose=0, mode='auto', epsilon=0.005, cooldown=0, min_lr=0.000001),\n",
    "#      keras.callbacks.EarlyStopping('val_loss', min_delta=0.001, patience=5, mode='min'),\n",
    "      keras.callbacks.ModelCheckpoint(\"model.hdf5\", save_best_only=True)]\n",
    "\n",
    "XX_train, XX_cv, YY_train, YY_cv = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "data_gen_args = dict(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=90.0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=1.0,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(XX_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(YY_train, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow(XX_train, batch_size=64, seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow(YY_train, batch_size=64, seed=seed)\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=len(XX_train)/64, epochs=40, \\\n",
    "                              validation_data=(XX_cv, YY_cv), callbacks=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
